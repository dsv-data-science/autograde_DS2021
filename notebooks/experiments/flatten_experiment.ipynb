{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Table of Contents\n",
    "* [1 Imports](#chapter1)\n",
    "* [2 Experiment](#chapter2)\n",
    "    * [2.1 Traditional methods](#section_2_1)\n",
    "    * [2.2 XLM-R](#section_2_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Imports <a class=\"anchor\" id=\"chapter1\"></a>\n",
    "* Import necessary libraries and data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "#libraries\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from utils import configs\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from statistics import mean\n",
    "from statistics import stdev\n",
    "import ktrain\n",
    "from ktrain import text\n",
    "from utils.experiment_models import RepeatedBaselines\n",
    "from utils.experiment_models import RandomClassifier as RC\n",
    "from utils.experiment_models import RepeatedBERT\n",
    "from utils import utils\n",
    "import numpy as np\n",
    "\n",
    "#data\n",
    "finalized_dataset = pd.read_csv('../../data/arabic_dataset.csv', index_col=0)\n",
    "\n",
    "#variables\n",
    "RANDOM_SEED = configs.RANDOM_SEED"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Experiment <a class=\"anchor\" id=\"chapter2\"></a>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "                         Question  \\\n0   عرف مصطلح الجريمة الإلكترونية   \n1   عرف مصطلح الجريمة الإلكترونية   \n2   عرف مصطلح الجريمة الإلكترونية   \n3   عرف مصطلح الجريمة الإلكترونية   \n4   عرف مصطلح الجريمة الإلكترونية   \n\n                                        Right_Answer  Grade Number  \\\n0   هي كل سلوك غير قانوني يتم باستخدام الأجهزة ال...  3.000    [1]   \n1   هي كل سلوك غير قانوني يتم باستخدام الأجهزة ال...  5.000    [2]   \n2   هي كل سلوك غير قانوني يتم باستخدام الأجهزة ال...  2.625    [3]   \n3   هي كل سلوك غير قانوني يتم باستخدام الأجهزة ال...  4.000    [4]   \n4   هي كل سلوك غير قانوني يتم باستخدام الأجهزة ال...  3.500    [5]   \n\n                                            Response  Question_Nr  Labels  \n0  هي سلوك غير أخلاقي يتم عن طريق وسائل الكترونية...            1       1  \n1  هي كل سلوك غير أخلاقي يتم بواسطة الاجهزة الالك...            1       1  \n2  هي سلوك غير قانوني يحمل باستعمال الأجهزة الالك...            1       1  \n3  هي سلوك غير قانوني تستخدم الوسائل الالكترونية ...            1       1  \n4  هي كل سلوك غير أخلاقي يتم باستخدام الوسائل الا...            1       1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Question</th>\n      <th>Right_Answer</th>\n      <th>Grade</th>\n      <th>Number</th>\n      <th>Response</th>\n      <th>Question_Nr</th>\n      <th>Labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>عرف مصطلح الجريمة الإلكترونية</td>\n      <td>هي كل سلوك غير قانوني يتم باستخدام الأجهزة ال...</td>\n      <td>3.000</td>\n      <td>[1]</td>\n      <td>هي سلوك غير أخلاقي يتم عن طريق وسائل الكترونية...</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>عرف مصطلح الجريمة الإلكترونية</td>\n      <td>هي كل سلوك غير قانوني يتم باستخدام الأجهزة ال...</td>\n      <td>5.000</td>\n      <td>[2]</td>\n      <td>هي كل سلوك غير أخلاقي يتم بواسطة الاجهزة الالك...</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>عرف مصطلح الجريمة الإلكترونية</td>\n      <td>هي كل سلوك غير قانوني يتم باستخدام الأجهزة ال...</td>\n      <td>2.625</td>\n      <td>[3]</td>\n      <td>هي سلوك غير قانوني يحمل باستعمال الأجهزة الالك...</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>عرف مصطلح الجريمة الإلكترونية</td>\n      <td>هي كل سلوك غير قانوني يتم باستخدام الأجهزة ال...</td>\n      <td>4.000</td>\n      <td>[4]</td>\n      <td>هي سلوك غير قانوني تستخدم الوسائل الالكترونية ...</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>عرف مصطلح الجريمة الإلكترونية</td>\n      <td>هي كل سلوك غير قانوني يتم باستخدام الأجهزة ال...</td>\n      <td>3.500</td>\n      <td>[5]</td>\n      <td>هي كل سلوك غير أخلاقي يتم باستخدام الوسائل الا...</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#renaming some columns to be the same name as other dataset\n",
    "finalized_dataset = finalized_dataset.rename(columns={'Number of Question': 'Question_Nr', 'label': 'Labels', 'Responses':'Response'})\n",
    "finalized_dataset.head(5)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#GLOBAL PARAMETERS\n",
    "TEST_SIZE = 0.15\n",
    "VALID_SIZE = 0.15\n",
    "ITERATIONS = 5\n",
    "METRICS = ['average_precision', 'roc_auc', 'spearman','averaged_classification_report']\n",
    "\n",
    "#GLOBAL DATA\n",
    "responses = finalized_dataset.Response\n",
    "labels = finalized_dataset.Labels\n",
    "corr_data = finalized_dataset.Grade"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.1 Traditional methods  <a class=\"anchor\" id=\"section_2_1\"></a>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "#FOR REPRESENTATION\n",
    "vectorizer = TfidfVectorizer(max_features=50000, ngram_range=(1,1))\n",
    "\n",
    "#MODELS\n",
    "#logistic regressor:\n",
    "regressor = LogisticRegression(max_iter=400,random_state=RANDOM_SEED)\n",
    "#random forest:\n",
    "rf = RandomForestClassifier(random_state=RANDOM_SEED)\n",
    "#1-nn:\n",
    "one_NN = KNeighborsClassifier(n_neighbors=1)\n",
    "#3-nn:\n",
    "three_NN = KNeighborsClassifier(n_neighbors=3)\n",
    "#random classifier:\n",
    "rc = RC.RandomClassifier(random_state=RANDOM_SEED, change_state=True)\n",
    "\n",
    "MODELS_MAP = {\n",
    "    'Logistic Regressor':regressor,\n",
    "    'Random Forest':rf,\n",
    "    '1-NN':one_NN,\n",
    "    '3-NN':three_NN,\n",
    "    'Random Classifier':rc\n",
    "}\n",
    "\n",
    "#REPEATED_HOLD_OUT MODEL USED FOR EXPERIMENTS\n",
    "rho = RepeatedBaselines.RepeatedBaselines(models=MODELS_MAP, metrics=METRICS, iterations=ITERATIONS, random_state=RANDOM_SEED)\n",
    "\n",
    "#FOR PRINTING RESULTS\n",
    "def print_results(results):\n",
    "    for model, result in results.items():\n",
    "\n",
    "      auprc_results = result['average_precision']\n",
    "      pos_label_scores = []\n",
    "      neg_label_scores = []\n",
    "      for neg, pos in auprc_results:\n",
    "          pos_label_scores.append(pos[1])\n",
    "          neg_label_scores.append(neg[1])\n",
    "\n",
    "      spearmans = [spearman for spearman, _ in result['spearman'] if not np.isnan(spearman)]\n",
    "      print('Model: {}. Iterations: {}'.format(model,ITERATIONS))\n",
    "      print('Average AUPRC (Positive: 0): {:0.2f}. Standard deviation: {:0.3f}.'.format(mean(neg_label_scores), stdev(neg_label_scores)))\n",
    "      print('Average AUPRC (Positive: 1): {:0.2f}. Standard deviation: {:0.3f}.'.format(mean(pos_label_scores), stdev(pos_label_scores)))\n",
    "      print('Average ROC AUC: {:0.2f}. Standard deviation: {:0.3f}.'.format(mean(result['roc_auc']), stdev(result['roc_auc'])))\n",
    "      print('Average Spearman correlation: {:0.2f}. Standard deviation: {:0.3f}.'.format(mean(spearmans), stdev(spearmans)))\n",
    "\n",
    "      report = result['averaged_classification_report']\n",
    "      formated_string = utils.format_report(report)\n",
    "      print(formated_string + '\\n\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regressor. Iterations: 5\n",
      "Average AUPRC (Positive: 0): 0.54. Standard deviation: 0.059.\n",
      "Average AUPRC (Positive: 1): 0.83. Standard deviation: 0.029.\n",
      "Average ROC AUC: 0.71. Standard deviation: 0.040.\n",
      "Average Spearman correlation: 0.41. Standard deviation: 0.062.\n",
      "0-> precision: 0.62, recall: 0.09, f1-score: 0.16, support: 108.40, \n",
      "1-> precision: 0.68, recall: 0.97, f1-score: 0.80, support: 211.60, \n",
      "accuracy-> 0.67\n",
      "macro avg-> precision: 0.65, recall: 0.53, f1-score: 0.48, support: 320.00, \n",
      "weighted avg-> precision: 0.66, recall: 0.67, f1-score: 0.58, support: 320.00, \n",
      "\n",
      "\n",
      "\n",
      "Model: Random Forest. Iterations: 5\n",
      "Average AUPRC (Positive: 0): 0.52. Standard deviation: 0.059.\n",
      "Average AUPRC (Positive: 1): 0.81. Standard deviation: 0.041.\n",
      "Average ROC AUC: 0.69. Standard deviation: 0.059.\n",
      "Average Spearman correlation: 0.39. Standard deviation: 0.110.\n",
      "0-> precision: 0.62, recall: 0.21, f1-score: 0.31, support: 108.40, \n",
      "1-> precision: 0.70, recall: 0.94, f1-score: 0.80, support: 211.60, \n",
      "accuracy-> 0.69\n",
      "macro avg-> precision: 0.66, recall: 0.57, f1-score: 0.55, support: 320.00, \n",
      "weighted avg-> precision: 0.67, recall: 0.69, f1-score: 0.63, support: 320.00, \n",
      "\n",
      "\n",
      "\n",
      "Model: 1-NN. Iterations: 5\n",
      "Average AUPRC (Positive: 0): 0.40. Standard deviation: 0.040.\n",
      "Average AUPRC (Positive: 1): 0.71. Standard deviation: 0.028.\n",
      "Average ROC AUC: 0.59. Standard deviation: 0.053.\n",
      "Average Spearman correlation: 0.27. Standard deviation: 0.066.\n",
      "0-> precision: 0.49, recall: 0.41, f1-score: 0.44, support: 108.40, \n",
      "1-> precision: 0.72, recall: 0.78, f1-score: 0.75, support: 211.60, \n",
      "accuracy-> 0.65\n",
      "macro avg-> precision: 0.60, recall: 0.59, f1-score: 0.60, support: 320.00, \n",
      "weighted avg-> precision: 0.64, recall: 0.65, f1-score: 0.65, support: 320.00, \n",
      "\n",
      "\n",
      "\n",
      "Model: 3-NN. Iterations: 5\n",
      "Average AUPRC (Positive: 0): 0.45. Standard deviation: 0.028.\n",
      "Average AUPRC (Positive: 1): 0.75. Standard deviation: 0.029.\n",
      "Average ROC AUC: 0.66. Standard deviation: 0.042.\n",
      "Average Spearman correlation: 0.36. Standard deviation: 0.054.\n",
      "0-> precision: 0.53, recall: 0.32, f1-score: 0.40, support: 108.40, \n",
      "1-> precision: 0.71, recall: 0.85, f1-score: 0.78, support: 211.60, \n",
      "accuracy-> 0.67\n",
      "macro avg-> precision: 0.62, recall: 0.59, f1-score: 0.59, support: 320.00, \n",
      "weighted avg-> precision: 0.65, recall: 0.67, f1-score: 0.65, support: 320.00, \n",
      "\n",
      "\n",
      "\n",
      "Model: Random Classifier. Iterations: 5\n",
      "Average AUPRC (Positive: 0): 0.34. Standard deviation: 0.009.\n",
      "Average AUPRC (Positive: 1): 0.67. Standard deviation: 0.011.\n",
      "Average ROC AUC: 0.51. Standard deviation: 0.021.\n",
      "Average Spearman correlation: 0.02. Standard deviation: 0.029.\n",
      "0-> precision: 0.33, recall: 0.49, f1-score: 0.40, support: 108.40, \n",
      "1-> precision: 0.66, recall: 0.49, f1-score: 0.56, support: 211.60, \n",
      "accuracy-> 0.49\n",
      "macro avg-> precision: 0.49, recall: 0.49, f1-score: 0.48, support: 320.00, \n",
      "weighted avg-> precision: 0.55, recall: 0.49, f1-score: 0.51, support: 320.00, \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "repeated_splits = rho.repeated_split(X=responses, y=labels, test_size=TEST_SIZE, valid_size=VALID_SIZE, stratify=labels)\n",
    "split_list = []\n",
    "\n",
    "for x_train, y_train, x_dev, y_dev, x_test, y_test, idx1, idx2 in repeated_splits:\n",
    "    split_list.append([x_train, x_test, y_train, y_test, idx1, idx2])\n",
    "\n",
    "conv_repeated_splits = rho.convert_data(split_list=split_list, representation=vectorizer)\n",
    "results = rho.fit_predict(split_list=conv_repeated_splits,correlation_data=corr_data)\n",
    "print_results(results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.2 XLM-R <a class=\"anchor\" id=\"section_2_2\"></a>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#FOR PRINTING RESULTS\n",
    "def print_results_bert(results):\n",
    "    spearmans = [spearman for spearman, _ in results['spearman']]\n",
    "\n",
    "    auprc_results = results['average_precision']\n",
    "    pos_label_scores = []\n",
    "    neg_label_scores = []\n",
    "    for neg, pos in auprc_results:\n",
    "        pos_label_scores.append(pos[1])\n",
    "        neg_label_scores.append(neg[1])\n",
    "\n",
    "    print('Model: XLM-R. Iterations: {}'.format(ITERATIONS))\n",
    "    print('Average AUPRC (Positive: 0): {:0.2f}. Standard deviation: {:0.3f}.'.format(mean(neg_label_scores), stdev(neg_label_scores)))\n",
    "    print('Average AUPRC (Positive: 1): {:0.2f}. Standard deviation: {:0.3f}.'.format(mean(pos_label_scores), stdev(pos_label_scores)))\n",
    "    print('Average ROC AUC: {:0.2f}. Standard deviation: {:0.3f}.'.format(mean(results['roc_auc']), stdev(results['roc_auc']) if len(results['average_precision']) > 1 else 0))\n",
    "    print('Average Spearman correlation: {:0.2f}. Standard deviation: {:0.3f}.'.format(mean(spearmans), stdev(spearmans) if len(spearmans) > 1 else 0))\n",
    "\n",
    "    report = results['averaged_classification_report']\n",
    "    formated_string = utils.format_report(report)\n",
    "    print(formated_string + '\\n\\n')\n",
    "\n",
    "#xlm-r parameters\n",
    "MODEL_NAME = \"xlm-roberta-base\"\n",
    "BATCH_SIZE = 6\n",
    "MAX_LEN = 200\n",
    "CLASS_NAMES = [0,1]\n",
    "EPOCHS = 30\n",
    "LR = 1e-5\n",
    "#xlm-r\n",
    "t = text.Transformer(MODEL_NAME, maxlen=200, class_names=CLASS_NAMES)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#scrambled merged experiment\n",
    "repeated_bert = RepeatedBERT.RepeatedBERT(transformer=t,metrics=METRICS,iterations=ITERATIONS,random_state=RANDOM_SEED)\n",
    "#get split_list\n",
    "split_list = repeated_bert.repeated_split(X=responses, y=labels,test_size=TEST_SIZE,valid_size=VALID_SIZE, stratify=labels)\n",
    "#fit and predict each split\n",
    "bert_results = repeated_bert.fit_predict(split_list=split_list,batch_size=BATCH_SIZE,epochs=EPOCHS,lr=LR,correlation_data=corr_data)\n",
    "#print results\n",
    "print_results_bert(bert_results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Code ran on COLAB, these were the results:\n",
    "# Model: XLM-R. Iterations: 5\n",
    "# Average AUPRC (Positive: 0): 0.60. Standard deviation: 0.026.\n",
    "# Average AUPRC (Positive: 1): 0.85. Standard deviation: 0.024.\n",
    "# Average ROC AUC: 0.75. Standard deviation: 0.030.\n",
    "# Average Spearman correlation: 0.48. Standard deviation: 0.040.\n",
    "# 0-> precision: 0.64, recall: 0.45, f1-score: 0.52, support: 108.40,\n",
    "# 1-> precision: 0.76, recall: 0.87, f1-score: 0.81, support: 211.60,\n",
    "# accuracy-> 0.73\n",
    "# macro avg-> precision: 0.70, recall: 0.66, f1-score: 0.66, support: 320.00,\n",
    "# weighted avg-> precision: 0.72, recall: 0.73, f1-score: 0.71, support: 320.00,"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}