{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Table of Contents\n",
    "* [1 Imports](#chapter1)\n",
    "* [2 Experiment](#chapter2)\n",
    "    * [2.1 Traditional methods](#section_2_1)\n",
    "    * [2.2 XLM-R](#section_2_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Imports <a class=\"anchor\" id=\"chapter1\"></a>\n",
    "* Import necessary libraries and data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "#libraries\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from utils import configs\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from statistics import mean\n",
    "from statistics import stdev\n",
    "from utils.experiment_models import RepeatedBaselines\n",
    "from utils.experiment_models import RepeatedBERT\n",
    "from utils.experiment_models import RandomClassifier as RC\n",
    "import numpy as np\n",
    "import ktrain\n",
    "from ktrain import text\n",
    "\n",
    "#data\n",
    "finalized_dataset = pd.read_csv('../../data/arabic_dataset.csv', index_col=0)\n",
    "\n",
    "#config variables\n",
    "RANDOM_SEED = configs.RANDOM_SEED"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Experiment <a class=\"anchor\" id=\"chapter2\"></a>\n",
    "* Train/test on questions individually"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "                         Question  \\\n0   عرف مصطلح الجريمة الإلكترونية   \n1   عرف مصطلح الجريمة الإلكترونية   \n2   عرف مصطلح الجريمة الإلكترونية   \n3   عرف مصطلح الجريمة الإلكترونية   \n4   عرف مصطلح الجريمة الإلكترونية   \n\n                                        Right_Answer  Grade Number  \\\n0   هي كل سلوك غير قانوني يتم باستخدام الأجهزة ال...  3.000    [1]   \n1   هي كل سلوك غير قانوني يتم باستخدام الأجهزة ال...  5.000    [2]   \n2   هي كل سلوك غير قانوني يتم باستخدام الأجهزة ال...  2.625    [3]   \n3   هي كل سلوك غير قانوني يتم باستخدام الأجهزة ال...  4.000    [4]   \n4   هي كل سلوك غير قانوني يتم باستخدام الأجهزة ال...  3.500    [5]   \n\n                                            Response  Question_Nr  Labels  \n0  هي سلوك غير أخلاقي يتم عن طريق وسائل الكترونية...            1       1  \n1  هي كل سلوك غير أخلاقي يتم بواسطة الاجهزة الالك...            1       1  \n2  هي سلوك غير قانوني يحمل باستعمال الأجهزة الالك...            1       1  \n3  هي سلوك غير قانوني تستخدم الوسائل الالكترونية ...            1       1  \n4  هي كل سلوك غير أخلاقي يتم باستخدام الوسائل الا...            1       1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Question</th>\n      <th>Right_Answer</th>\n      <th>Grade</th>\n      <th>Number</th>\n      <th>Response</th>\n      <th>Question_Nr</th>\n      <th>Labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>عرف مصطلح الجريمة الإلكترونية</td>\n      <td>هي كل سلوك غير قانوني يتم باستخدام الأجهزة ال...</td>\n      <td>3.000</td>\n      <td>[1]</td>\n      <td>هي سلوك غير أخلاقي يتم عن طريق وسائل الكترونية...</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>عرف مصطلح الجريمة الإلكترونية</td>\n      <td>هي كل سلوك غير قانوني يتم باستخدام الأجهزة ال...</td>\n      <td>5.000</td>\n      <td>[2]</td>\n      <td>هي كل سلوك غير أخلاقي يتم بواسطة الاجهزة الالك...</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>عرف مصطلح الجريمة الإلكترونية</td>\n      <td>هي كل سلوك غير قانوني يتم باستخدام الأجهزة ال...</td>\n      <td>2.625</td>\n      <td>[3]</td>\n      <td>هي سلوك غير قانوني يحمل باستعمال الأجهزة الالك...</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>عرف مصطلح الجريمة الإلكترونية</td>\n      <td>هي كل سلوك غير قانوني يتم باستخدام الأجهزة ال...</td>\n      <td>4.000</td>\n      <td>[4]</td>\n      <td>هي سلوك غير قانوني تستخدم الوسائل الالكترونية ...</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>عرف مصطلح الجريمة الإلكترونية</td>\n      <td>هي كل سلوك غير قانوني يتم باستخدام الأجهزة ال...</td>\n      <td>3.500</td>\n      <td>[5]</td>\n      <td>هي كل سلوك غير أخلاقي يتم باستخدام الوسائل الا...</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#renaming some columns to be the same name as other dataset\n",
    "finalized_dataset = finalized_dataset.rename(columns={'Number of Question': 'Question_Nr', 'label': 'Labels', 'Responses':'Response'})\n",
    "finalized_dataset.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "#global parameters\n",
    "TEST_SIZE = 0.15\n",
    "VALID_SIZE = 0.15\n",
    "ITERATIONS = 10\n",
    "METRICS = ['average_precision', 'spearman', 'roc_auc', 'averaged_classification_report']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.1 Traditional methods  <a class=\"anchor\" id=\"section_2_1\"></a>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "#for representation\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,1))\n",
    "\n",
    "#MODELS\n",
    "#logistic regressor:\n",
    "regressor = LogisticRegression(max_iter=400,random_state=RANDOM_SEED)\n",
    "#random forest:\n",
    "rf = RandomForestClassifier(random_state=RANDOM_SEED)\n",
    "#1-nn:\n",
    "one_NN = KNeighborsClassifier(n_neighbors=1)\n",
    "#3-nn:\n",
    "three_NN = KNeighborsClassifier(n_neighbors=3)\n",
    "#random classifier:\n",
    "rc = RC.RandomClassifier(random_state=RANDOM_SEED, change_state=True)\n",
    "\n",
    "MODELS_MAP = {\n",
    "    'Logistic Regressor':regressor,\n",
    "    'Random Forest':rf,\n",
    "    '1-NN':one_NN,\n",
    "    '3-NN':three_NN,\n",
    "    'Random Classifier':rc\n",
    "}\n",
    "\n",
    "#Create RepeatedBaseLines object for experiments. (See RepeatedBaseLines.py in utils>experiment_models>RepeatedBaselines)\n",
    "rho = RepeatedBaselines.RepeatedBaselines(models=MODELS_MAP, metrics=METRICS, iterations=ITERATIONS, random_state=RANDOM_SEED)\n",
    "\n",
    "#FOR SIMPLE FORMATTING OF CLASSIFICATION REPORT\n",
    "def format_report(report):\n",
    "  formated_report = ''\n",
    "  for label, metrics in report.items():\n",
    "      formated_report += '{}-> '.format(label)\n",
    "      if type(metrics) == dict:\n",
    "          for metric, score in metrics.items():\n",
    "            formated_report += '{}: {:.2f}, '.format(metric, score)\n",
    "      else:\n",
    "          formated_report += '{:.2f}'.format(metrics)\n",
    "      formated_report += '\\n'\n",
    "\n",
    "  return formated_report\n",
    "\n",
    "#FOR PRINTING RESULTS\n",
    "def print_results(results):\n",
    "    for model, result in results.items():\n",
    "      spearmans = [spearman for spearman, _ in result['spearman'] if not np.isnan(spearman)]\n",
    "\n",
    "      auprc_results = result['average_precision']\n",
    "      pos_label_scores = []\n",
    "      neg_label_scores = []\n",
    "      for neg, pos in auprc_results:\n",
    "          pos_label_scores.append(pos[1])\n",
    "          neg_label_scores.append(neg[1])\n",
    "\n",
    "      print('Model: {}. Iterations: {}'.format(model,ITERATIONS))\n",
    "      print('Average AUPRC (Positive: 0): {:0.2f}. Standard deviation: {:0.3f}.'.format(mean(neg_label_scores), stdev(neg_label_scores)))\n",
    "      print('Average AUPRC (Positive: 1): {:0.2f}. Standard deviation: {:0.3f}.'.format(mean(pos_label_scores), stdev(pos_label_scores)))\n",
    "      print('Average ROC AUC: {:0.2f}. Standard deviation: {:0.3f}.'.format(mean(result['roc_auc']), stdev(result['roc_auc'])))\n",
    "      if spearmans:\n",
    "        print('Average Spearman correlation: {:0.2f}. Standard deviation: {:0.3f}.'.format(mean(spearmans), stdev(spearmans)))\n",
    "      else:\n",
    "        print('Spearman: NaN')\n",
    "\n",
    "      report = result['averaged_classification_report']\n",
    "      formated_string = format_report(report)\n",
    "      print(formated_string + '\\n\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ljung\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\ljung\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\ljung\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\ljung\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\ljung\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\ljung\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\scipy\\stats\\stats.py:4196: SpearmanRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(SpearmanRConstantInputWarning())\n",
      "c:\\users\\ljung\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\ljung\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\ljung\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\scipy\\stats\\stats.py:4196: SpearmanRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(SpearmanRConstantInputWarning())\n",
      "c:\\users\\ljung\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\ljung\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\ljung\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\ljung\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\ljung\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\ljung\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\ljung\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\ljung\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\ljung\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\ljung\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\ljung\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\ljung\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\scipy\\stats\\stats.py:4196: SpearmanRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(SpearmanRConstantInputWarning())\n",
      "c:\\users\\ljung\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\ljung\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\ljung\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\ljung\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\ljung\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\ljung\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\ljung\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\ljung\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\ljung\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regressor. Iterations: 10\n",
      "Average AUPRC (Positive: 0): 0.84. Standard deviation: 0.218.\n",
      "Average AUPRC (Positive: 1): 0.98. Standard deviation: 0.029.\n",
      "Average ROC AUC: 0.92. Standard deviation: 0.114.\n",
      "Average Spearman correlation: 0.53. Standard deviation: 0.252.\n",
      "0-> precision: 0.00, recall: 0.00, f1-score: 0.00, support: 2.00, \n",
      "1-> precision: 0.78, recall: 1.00, f1-score: 0.88, support: 7.00, \n",
      "accuracy-> 0.78\n",
      "macro avg-> precision: 0.39, recall: 0.50, f1-score: 0.44, support: 9.00, \n",
      "weighted avg-> precision: 0.60, recall: 0.78, f1-score: 0.68, support: 9.00, \n",
      "\n",
      "\n",
      "\n",
      "Model: Random Forest. Iterations: 10\n",
      "Average AUPRC (Positive: 0): 0.77. Standard deviation: 0.234.\n",
      "Average AUPRC (Positive: 1): 0.97. Standard deviation: 0.035.\n",
      "Average ROC AUC: 0.90. Standard deviation: 0.132.\n",
      "Average Spearman correlation: 0.54. Standard deviation: 0.224.\n",
      "0-> precision: 0.00, recall: 0.00, f1-score: 0.00, support: 2.00, \n",
      "1-> precision: 0.78, recall: 1.00, f1-score: 0.88, support: 7.00, \n",
      "accuracy-> 0.78\n",
      "macro avg-> precision: 0.39, recall: 0.50, f1-score: 0.44, support: 9.00, \n",
      "weighted avg-> precision: 0.60, recall: 0.78, f1-score: 0.68, support: 9.00, \n",
      "\n",
      "\n",
      "\n",
      "Model: 1-NN. Iterations: 10\n",
      "Average AUPRC (Positive: 0): 0.54. Standard deviation: 0.249.\n",
      "Average AUPRC (Positive: 1): 0.87. Standard deviation: 0.080.\n",
      "Average ROC AUC: 0.71. Standard deviation: 0.185.\n",
      "Average Spearman correlation: 0.53. Standard deviation: 0.134.\n",
      "0-> precision: 0.67, recall: 0.45, f1-score: 0.51, support: 2.00, \n",
      "1-> precision: 0.87, recall: 0.97, f1-score: 0.91, support: 7.00, \n",
      "accuracy-> 0.86\n",
      "macro avg-> precision: 0.77, recall: 0.71, f1-score: 0.71, support: 9.00, \n",
      "weighted avg-> precision: 0.82, recall: 0.86, f1-score: 0.82, support: 9.00, \n",
      "\n",
      "\n",
      "\n",
      "Model: 3-NN. Iterations: 10\n",
      "Average AUPRC (Positive: 0): 0.62. Standard deviation: 0.251.\n",
      "Average AUPRC (Positive: 1): 0.89. Standard deviation: 0.080.\n",
      "Average ROC AUC: 0.76. Standard deviation: 0.177.\n",
      "Average Spearman correlation: 0.51. Standard deviation: 0.171.\n",
      "0-> precision: 0.50, recall: 0.30, f1-score: 0.37, support: 2.00, \n",
      "1-> precision: 0.84, recall: 1.00, f1-score: 0.91, support: 7.00, \n",
      "accuracy-> 0.84\n",
      "macro avg-> precision: 0.67, recall: 0.65, f1-score: 0.64, support: 9.00, \n",
      "weighted avg-> precision: 0.76, recall: 0.84, f1-score: 0.79, support: 9.00, \n",
      "\n",
      "\n",
      "\n",
      "Model: Random Classifier. Iterations: 10\n",
      "Average AUPRC (Positive: 0): 0.26. Standard deviation: 0.055.\n",
      "Average AUPRC (Positive: 1): 0.78. Standard deviation: 0.060.\n",
      "Average ROC AUC: 0.45. Standard deviation: 0.206.\n",
      "Average Spearman correlation: -0.09. Standard deviation: 0.484.\n",
      "0-> precision: 0.20, recall: 0.45, f1-score: 0.27, support: 2.00, \n",
      "1-> precision: 0.75, recall: 0.49, f1-score: 0.57, support: 7.00, \n",
      "accuracy-> 0.48\n",
      "macro avg-> precision: 0.47, recall: 0.47, f1-score: 0.42, support: 9.00, \n",
      "weighted avg-> precision: 0.63, recall: 0.48, f1-score: 0.50, support: 9.00, \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "################QUESTION 13########################\n",
    "responses = finalized_dataset[finalized_dataset.Question_Nr == 13].Response\n",
    "labels = finalized_dataset[finalized_dataset.Question_Nr == 13].Labels\n",
    "corr_data = finalized_dataset[finalized_dataset.Question_Nr == 13].Grade\n",
    "\n",
    "repeated_splits = rho.repeated_split(X=responses, y=labels, test_size=TEST_SIZE, valid_size=VALID_SIZE, stratify=labels)\n",
    "split_list = []\n",
    "for x_train, y_train, x_dev, y_dev, x_test, y_test, idx1, idx2 in repeated_splits:\n",
    "    split_list.append([x_train, x_test, y_train, y_test, idx1, idx2])\n",
    "conv_repeated_splits = rho.convert_data(split_list=split_list, representation=vectorizer)\n",
    "results = rho.fit_predict(split_list=conv_repeated_splits,correlation_data=corr_data)\n",
    "print_results(results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ljung\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\ljung\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\ljung\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\ljung\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\scipy\\stats\\stats.py:4196: SpearmanRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(SpearmanRConstantInputWarning())\n",
      "c:\\users\\ljung\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\ljung\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\ljung\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\ljung\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regressor. Iterations: 10\n",
      "Average AUPRC (Positive: 0): 0.81. Standard deviation: 0.198.\n",
      "Average AUPRC (Positive: 1): 0.82. Standard deviation: 0.208.\n",
      "Average ROC AUC: 0.77. Standard deviation: 0.251.\n",
      "Average Spearman correlation: 0.55. Standard deviation: 0.440.\n",
      "0-> precision: 0.82, recall: 0.59, f1-score: 0.63, support: 3.30, \n",
      "1-> precision: 0.61, recall: 0.78, f1-score: 0.68, support: 3.70, \n",
      "accuracy-> 0.69\n",
      "macro avg-> precision: 0.72, recall: 0.69, f1-score: 0.66, support: 7.00, \n",
      "weighted avg-> precision: 0.71, recall: 0.69, f1-score: 0.66, support: 7.00, \n",
      "\n",
      "\n",
      "\n",
      "Model: Random Forest. Iterations: 10\n",
      "Average AUPRC (Positive: 0): 0.91. Standard deviation: 0.154.\n",
      "Average AUPRC (Positive: 1): 0.94. Standard deviation: 0.115.\n",
      "Average ROC AUC: 0.91. Standard deviation: 0.153.\n",
      "Average Spearman correlation: 0.78. Standard deviation: 0.159.\n",
      "0-> precision: 0.77, recall: 1.00, f1-score: 0.85, support: 3.30, \n",
      "1-> precision: 0.80, recall: 0.62, f1-score: 0.68, support: 3.70, \n",
      "accuracy-> 0.80\n",
      "macro avg-> precision: 0.78, recall: 0.81, f1-score: 0.77, support: 7.00, \n",
      "weighted avg-> precision: 0.78, recall: 0.80, f1-score: 0.76, support: 7.00, \n",
      "\n",
      "\n",
      "\n",
      "Model: 1-NN. Iterations: 10\n",
      "Average AUPRC (Positive: 0): 0.52. Standard deviation: 0.131.\n",
      "Average AUPRC (Positive: 1): 0.55. Standard deviation: 0.125.\n",
      "Average ROC AUC: 0.50. Standard deviation: 0.184.\n",
      "Average Spearman correlation: -0.12. Standard deviation: 0.499.\n",
      "0-> precision: 0.44, recall: 0.44, f1-score: 0.43, support: 3.30, \n",
      "1-> precision: 0.49, recall: 0.55, f1-score: 0.51, support: 3.70, \n",
      "accuracy-> 0.51\n",
      "macro avg-> precision: 0.46, recall: 0.50, f1-score: 0.47, support: 7.00, \n",
      "weighted avg-> precision: 0.48, recall: 0.51, f1-score: 0.49, support: 7.00, \n",
      "\n",
      "\n",
      "\n",
      "Model: 3-NN. Iterations: 10\n",
      "Average AUPRC (Positive: 0): 0.63. Standard deviation: 0.127.\n",
      "Average AUPRC (Positive: 1): 0.66. Standard deviation: 0.158.\n",
      "Average ROC AUC: 0.66. Standard deviation: 0.157.\n",
      "Average Spearman correlation: 0.32. Standard deviation: 0.359.\n",
      "0-> precision: 0.56, recall: 0.30, f1-score: 0.35, support: 3.30, \n",
      "1-> precision: 0.56, recall: 0.83, f1-score: 0.65, support: 3.70, \n",
      "accuracy-> 0.59\n",
      "macro avg-> precision: 0.56, recall: 0.57, f1-score: 0.50, support: 7.00, \n",
      "weighted avg-> precision: 0.58, recall: 0.59, f1-score: 0.52, support: 7.00, \n",
      "\n",
      "\n",
      "\n",
      "Model: Random Classifier. Iterations: 10\n",
      "Average AUPRC (Positive: 0): 0.51. Standard deviation: 0.151.\n",
      "Average AUPRC (Positive: 1): 0.57. Standard deviation: 0.108.\n",
      "Average ROC AUC: 0.50. Standard deviation: 0.194.\n",
      "Average Spearman correlation: 0.02. Standard deviation: 0.366.\n",
      "0-> precision: 0.48, recall: 0.44, f1-score: 0.43, support: 3.30, \n",
      "1-> precision: 0.59, recall: 0.66, f1-score: 0.59, support: 3.70, \n",
      "accuracy-> 0.54\n",
      "macro avg-> precision: 0.54, recall: 0.55, f1-score: 0.51, support: 7.00, \n",
      "weighted avg-> precision: 0.55, recall: 0.54, f1-score: 0.51, support: 7.00, \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "################QUESTION 33########################\n",
    "responses = finalized_dataset[finalized_dataset.Question_Nr == 33].Response\n",
    "labels = finalized_dataset[finalized_dataset.Question_Nr == 33].Labels\n",
    "corr_data = finalized_dataset[finalized_dataset.Question_Nr == 33].Grade\n",
    "\n",
    "repeated_splits = rho.repeated_split(X=responses, y=labels, test_size=TEST_SIZE, valid_size=VALID_SIZE, stratify=labels)\n",
    "split_list = []\n",
    "for x_train, y_train, x_dev, y_dev, x_test, y_test, idx1, idx2 in repeated_splits:\n",
    "    split_list.append([x_train, x_test, y_train, y_test, idx1, idx2])\n",
    "conv_repeated_splits = rho.convert_data(split_list=split_list, representation=vectorizer)\n",
    "results = rho.fit_predict(split_list=conv_repeated_splits,correlation_data=corr_data)\n",
    "print_results(results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.2 XLM-R <a class=\"anchor\" id=\"section_2_2\"></a>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "#FOR PRINTING RESULTS\n",
    "def print_results_bert(results):\n",
    "    spearmans = [spearman for spearman, _ in results['spearman']]\n",
    "\n",
    "    auprc_results = results['average_precision']\n",
    "    pos_label_scores = []\n",
    "    neg_label_scores = []\n",
    "    for neg, pos in auprc_results:\n",
    "        pos_label_scores.append(pos[1])\n",
    "        neg_label_scores.append(neg[1])\n",
    "\n",
    "    print('Model: XLM-R. Iterations: {}'.format(ITERATIONS))\n",
    "    print('Average AUPRC (Positive: 0): {:0.2f}. Standard deviation: {:0.3f}.'.format(mean(neg_label_scores), stdev(neg_label_scores)))\n",
    "    print('Average AUPRC (Positive: 1): {:0.2f}. Standard deviation: {:0.3f}.'.format(mean(pos_label_scores), stdev(pos_label_scores)))\n",
    "    print('Average ROC AUC: {:0.2f}. Standard deviation: {:0.3f}.'.format(mean(results['roc_auc']), stdev(results['roc_auc']) if len(results['average_precision']) > 1 else 0))\n",
    "    print('Average Spearman correlation: {:0.2f}. Standard deviation: {:0.3f}.'.format(mean(spearmans), stdev(spearmans) if len(spearmans) > 1 else 0))\n",
    "\n",
    "    report = results['averaged_classification_report']\n",
    "    formated_string = format_report(report)\n",
    "    print(formated_string + '\\n\\n')\n",
    "\n",
    "#xlm-r parameters\n",
    "MODEL_NAME = \"xlm-roberta-base\"\n",
    "BATCH_SIZE = 6\n",
    "MAX_LEN = 200\n",
    "CLASS_NAMES = [0,1]\n",
    "EPOCHS = 30\n",
    "LR = 1e-5\n",
    "#xlm-r\n",
    "t = text.Transformer(MODEL_NAME, maxlen=200, class_names=CLASS_NAMES)\n",
    "#Create RepeatedBert object for experiments. (See RepeatedBERT.py in utils>experiment_models>RepeatedBERT)\n",
    "repeated_bert = RepeatedBERT.RepeatedBERT(transformer=t,metrics=METRICS,iterations=ITERATIONS,random_state=RANDOM_SEED)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "################QUESTION 13########################\n",
    "responses = finalized_dataset[finalized_dataset.Question_Nr == 13].Response\n",
    "labels = finalized_dataset[finalized_dataset.Question_Nr == 13].Labels\n",
    "corr_data = finalized_dataset[finalized_dataset.Question_Nr == 13].Grade\n",
    "\n",
    "#create list of splits\n",
    "split_list = repeated_bert.repeated_split(X=responses, y=labels,test_size=TEST_SIZE,valid_size=VALID_SIZE, stratify=labels)\n",
    "#fit and predict each split\n",
    "bert_results = repeated_bert.fit_predict(split_list=split_list,batch_size=BATCH_SIZE,epochs=EPOCHS,lr=LR,correlation_data=corr_data)\n",
    "#print results\n",
    "print_results_bert(bert_results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "################QUESTION 33########################\n",
    "responses = finalized_dataset[finalized_dataset.Question_Nr == 33].Response\n",
    "labels = finalized_dataset[finalized_dataset.Question_Nr == 33].Labels\n",
    "corr_data = finalized_dataset[finalized_dataset.Question_Nr == 33].Grade\n",
    "\n",
    "split_list = repeated_bert.repeated_split(X=responses, y=labels,test_size=TEST_SIZE,valid_size=VALID_SIZE, stratify=labels)\n",
    "bert_results = repeated_bert.fit_predict(split_list=split_list,batch_size=BATCH_SIZE,epochs=EPOCHS,lr=LR,correlation_data=corr_data)\n",
    "print_results_bert(bert_results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "#CODE RAN ON COLAB. THESE WERE THE RESULTS:\n",
    "#RESULTS Q13:\n",
    "# Model: XLM-R. Iterations: 10\n",
    "# Average AUPRC (Positive: 0): 0.95. Standard deviation: 0.158.\n",
    "# Average AUPRC (Positive: 1): 0.99. Standard deviation: 0.016.\n",
    "# Average ROC AUC: 0.98. Standard deviation: 0.068.\n",
    "# Average Spearman correlation: 0.65. Standard deviation: 0.148.\n",
    "# 0-> precision: 0.85, recall: 0.75, f1-score: 0.78, support: 2.00,\n",
    "# 1-> precision: 0.94, recall: 0.99, f1-score: 0.96, support: 7.00,\n",
    "# accuracy-> 0.93\n",
    "# macro avg-> precision: 0.89, recall: 0.87, f1-score: 0.87, support: 9.00,\n",
    "# weighted avg-> precision: 0.92, recall: 0.93, f1-score: 0.92, support: 9.00,\n",
    "\n",
    "#RESULTS Q33:\n",
    "# Model: XLM-R. Iterations: 10\n",
    "# Average AUPRC (Positive: 0): 0.94. Standard deviation: 0.071.\n",
    "# Average AUPRC (Positive: 1): 0.95. Standard deviation: 0.064.\n",
    "# Average ROC AUC: 0.93. Standard deviation: 0.092.\n",
    "# Average Spearman correlation: 0.81. Standard deviation: 0.084.\n",
    "# 0-> precision: 0.78, recall: 0.75, f1-score: 0.73, support: 3.30,\n",
    "# 1-> precision: 0.86, recall: 0.81, f1-score: 0.77, support: 3.70,\n",
    "# accuracy-> 0.79\n",
    "# macro avg-> precision: 0.82, recall: 0.78, f1-score: 0.75, support: 7.00,\n",
    "# weighted avg-> precision: 0.82, recall: 0.79, f1-score: 0.76, support: 7.00,"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}